"""Monitoring primitives for oellm_autoexp."""

from __future__ import annotations

import time
from dataclasses import dataclass, field, MISSING
import re
from typing import Any
from collections.abc import Iterable
from re import Pattern
from pathlib import Path

from compoconf import ConfigInterface, register

from oellm_autoexp.config.schema import MonitorInterface
from oellm_autoexp.monitor.actions import LogActionConfig
from oellm_autoexp.monitor.event_bindings import (
    EventActionBinding,
    EventActionConfig,
    instantiate_bindings,
)
from oellm_autoexp.monitor.states import (
    BaseMonitorState,
    CrashState,
    CrashStateConfig,
    MonitorStateInterface,
    StalledState,
    StalledStateConfig,
    SuccessState,
    SuccessStateConfig,
    TimeoutState,
    TimeoutStateConfig,
)
from oellm_autoexp.utils.run import run_with_tee


@dataclass(frozen=True)
class MonitoredJob:
    """Metadata describing an active job to be inspected."""

    job_id: str = field(default_factory=MISSING)
    name: str = field(default_factory=MISSING)
    log_path: str = field(default_factory=MISSING)
    check_interval_seconds: int = field(default_factory=MISSING)
    state: str = field(default_factory=MISSING)
    termination_string: str | None = None
    termination_command: str | None = None
    metadata: dict[str, Any] = field(default_factory=dict)
    output_paths: list[str] = field(default_factory=list)


@dataclass(kw_only=True)
class MonitorOutcome:
    """Snapshot emitted by a monitor iteration."""

    job_id: str = field(default_factory=MISSING)
    status: str = field(default_factory=MISSING)
    last_update_seconds: float | None
    metadata: dict[str, Any] = field(default_factory=dict)
    events: list[MonitorEvent] = field(default_factory=list)


@dataclass(kw_only=True)
class MonitorEvent:
    """Event detected by the monitor while inspecting a job."""

    job_id: str = field(default_factory=MISSING)
    name: str = field(default_factory=MISSING)
    state: BaseMonitorState | None = None
    metadata: dict[str, Any] = field(default_factory=dict)
    actions: list[EventActionBinding] = field(default_factory=list)


class BaseMonitor(MonitorInterface):
    """Base class monitors can inherit from to gain a common signature."""

    config: ConfigInterface

    def __init__(self, config: ConfigInterface) -> None:
        self.config = config

    async def watch(
        self, jobs: Iterable[MonitoredJob]
    ) -> dict[str, MonitorOutcome]:  # pragma: no cover
        raise NotImplementedError


@dataclass(kw_only=True)
class NullMonitorConfig(ConfigInterface):
    """Monitor configuration that performs no observation."""

    class_name: str = "NullMonitor"
    poll_interval_seconds: int = 600
    inactivity_threshold_seconds: int | None = 900
    termination_string: str | None = None
    termination_command: str | None = None
    log_path_template: str = "{output_dir}/slurm-%j.out"
    output_paths: list[str] = field(default_factory=list)
    start_condition_cmd: str | None = None
    start_condition_interval_seconds: int | None = None
    state_events: list[StateEventConfig] = field(default_factory=list)


@dataclass(kw_only=True)
class LogEventConfig(ConfigInterface):
    """Configuration describing a log-derived event."""

    class_name: str = "LogEvent"
    name: str
    pattern: str
    state: MonitorStateInterface.cfgtype | None = None
    actions: list[EventActionConfig] = field(default_factory=list)
    pattern_type: str = "regex"
    metadata: dict[str, Any] = field(default_factory=dict)
    extract_groups: dict[str, str | int] = field(default_factory=dict)

    def __post_init__(self) -> None:
        if self.state is None and not self.metadata:
            raise ValueError(
                f"LogEventConfig '{self.name}' must specify a state change or metadata payload"
            )
        if self.pattern_type not in {"regex", "substring"}:
            raise ValueError(f"Unsupported pattern_type {self.pattern_type!r} for '{self.name}'")


# Backwards compatibility alias to ease config migration.
LogSignalConfig = LogEventConfig


@dataclass(kw_only=True)
class StateEventConfig(ConfigInterface):
    """Configuration describing a synthetic event generated by
    classification."""

    class_name: str = "StateEvent"
    name: str
    state: MonitorStateInterface.cfgtype | None = None
    metadata: dict[str, Any] = field(default_factory=dict)
    actions: list[EventActionConfig] = field(default_factory=list)


@register
class NullMonitor(BaseMonitor):
    config: NullMonitorConfig

    async def watch(self, jobs: Iterable[MonitoredJob]) -> dict[str, MonitorOutcome]:
        return {}


@dataclass(kw_only=True)
class SlurmLogMonitorConfig(NullMonitorConfig):
    """Monitor that inspects SLURM logs for stalls or completion markers."""

    class_name: str = "SlurmLogMonitor"
    inactivity_threshold_seconds: int | None = 900
    check_interval_seconds: int = 300
    log_events: list[LogEventConfig] = field(default_factory=list)
    output_paths: list[str] = field(default_factory=list)
    state_whitelist: list[str] = field(default_factory=lambda: ["pending", "running", "stall"])
    state_events: list[StateEventConfig] = field(default_factory=list)


@register
class SlurmLogMonitor(BaseMonitor):
    config: SlurmLogMonitorConfig

    def __init__(self, config: SlurmLogMonitorConfig) -> None:
        super().__init__(config)
        if not config.log_events:
            config.log_events = default_log_events()
        if not config.state_events:
            config.state_events = default_state_events()
        self._snapshots: dict[str, _JobSnapshot] = {}
        self._state_whitelist = {state.lower() for state in config.state_whitelist}
        self._state_event_map: dict[str, StateEventConfig] = {
            state_event.name: state_event for state_event in config.state_events
        }
        self._compiled_rules: list[_CompiledLogEvent] = [
            _CompiledLogEvent(
                rule=rule,
                pattern=_compile_pattern(rule),
            )
            for rule in config.log_events
        ]

    async def watch(self, jobs: Iterable[MonitoredJob]) -> dict[str, MonitorOutcome]:
        now = time.time()
        observations: dict[str, MonitorOutcome] = {}
        for job in jobs:
            outcome = self._evaluate_job(job, now)
            observations[job.job_id] = outcome
        return observations

    def _evaluate_job(self, job: MonitoredJob, now: float) -> MonitorOutcome:
        if self._state_whitelist and job.state.lower() not in self._state_whitelist:
            return MonitorOutcome(
                job_id=job.job_id,
                status=job.state,
                last_update_seconds=None,
                metadata={},
                events=[],
            )

        log_path = Path(job.log_path)
        status = "pending"
        last_update_seconds: float | None = None
        metadata: dict[str, Any] = {}
        events: list[MonitorEvent] = []
        snapshot = self._snapshots.get(job.job_id)
        updated = False

        termination_event = self._check_termination(job)
        if termination_event:
            status = "complete"
            metadata.update(termination_event.metadata)
            events.append(termination_event)
            snapshot = _JobSnapshot(log_content="", last_update=now)
            snapshot.output_contents = {}
            self._snapshots[job.job_id] = snapshot
            return MonitorOutcome(
                job_id=job.job_id,
                status=status,
                last_update_seconds=0.0,
                metadata=metadata,
                events=events,
            )

        log_previous = snapshot.log_content if snapshot else ""
        log_current = log_previous
        if log_path.exists():
            try:
                log_current = log_path.read_text(errors="ignore")
            except OSError:
                log_current = ""
            if log_current != log_previous:
                events.extend(
                    self._extract_events(
                        job,
                        log_current,
                        log_previous,
                        source="log",
                        source_path=log_path,
                    )
                )
                updated = True
        else:
            log_current = ""

        output_contents = dict(snapshot.output_contents) if snapshot else {}
        for output_path in job.output_paths:
            try:
                content = Path(output_path).read_text(errors="ignore")
            except OSError:
                content = ""
            previous = output_contents.get(output_path, "")
            if content != previous:
                events.extend(
                    self._extract_events(
                        job,
                        content,
                        previous,
                        source="output",
                        source_path=output_path,
                    )
                )
                output_contents[output_path] = content
                updated = True

        if snapshot is None:
            snapshot = _JobSnapshot(log_content=log_current, last_update=now)
        snapshot.log_content = log_current
        snapshot.output_contents = output_contents
        if updated:
            snapshot.last_update = now
            last_update_seconds = 0.0
            status = "active"
        else:
            if snapshot.log_content or snapshot.output_contents:
                last_update_seconds = now - snapshot.last_update
                threshold = self._effective_threshold(job)
                if threshold is not None and last_update_seconds >= threshold:
                    status = "stall"
                else:
                    status = "active"
            else:
                status = "pending"
                last_update_seconds = None

        self._snapshots[job.job_id] = snapshot

        return MonitorOutcome(
            job_id=job.job_id,
            status=status,
            last_update_seconds=last_update_seconds,
            metadata=metadata,
            events=events,
        )

    def _extract_events(
        self,
        job: MonitoredJob,
        content: str,
        previous: str,
        *,
        source: str,
        source_path: str | None = None,
    ) -> list[MonitorEvent]:
        events: list[MonitorEvent] = []
        if not self._compiled_rules:
            return events

        new_text = content
        if previous and content.startswith(previous):
            new_text = content[len(previous) :]  # noqa

        if not new_text:
            return events

        for compiled in self._compiled_rules:
            rule = compiled.rule
            for match in compiled.pattern.finditer(new_text):
                metadata = dict(rule.metadata)
                extracted = _extract_metadata(match, rule)
                metadata.update(extracted)
                metadata.setdefault("job_name", job.name)
                if source_path is not None:
                    metadata.setdefault("source_path", str(source_path))
                metadata.setdefault("source", source)
                state_instance = compiled.instantiate_state()
                bindings = instantiate_bindings(rule.actions)
                events.append(
                    MonitorEvent(
                        job_id=job.job_id,
                        name=rule.name,
                        state=state_instance,
                        metadata=metadata,
                        actions=bindings,
                    )
                )
        return events

    def _effective_threshold(self, job: MonitoredJob) -> int | None:
        if job.metadata.get("inactivity_threshold_seconds") is not None:
            return job.metadata["inactivity_threshold_seconds"]
        return self.config.inactivity_threshold_seconds

    def _check_termination(self, job: MonitoredJob) -> MonitorEvent | None:
        log_path = Path(job.log_path)
        metadata: dict[str, Any] = {}
        termination_string = job.termination_string or self.config.termination_string
        if termination_string and log_path.exists():
            try:
                content = log_path.read_text(errors="ignore")
            except OSError:
                content = ""
            if termination_string in content:
                metadata.update(
                    {
                        "reason": "termination-string",
                        "log_path": str(log_path),
                    }
                )
                event = self._build_state_event(job, "success", metadata)
                if event:
                    return event

        command = job.termination_command or self.config.termination_command
        if command:
            proc = run_with_tee(command, shell=True, capture_output=True, check=False, text=True)
            try:
                exit_value = int(proc.stdout.strip() or proc.returncode)
            except ValueError:
                exit_value = proc.returncode
            if exit_value == 1:
                metadata.update(
                    {
                        "reason": "termination-command",
                        "command": command,
                    }
                )
                event = self._build_state_event(job, "success", metadata)
                if event:
                    return event

        return None

    def _build_state_event(
        self,
        job: MonitoredJob,
        name: str,
        extra_metadata: dict[str, Any],
    ) -> MonitorEvent | None:
        cfg = self._state_event_map.get(name)
        metadata = dict(cfg.metadata if cfg else {})
        metadata.setdefault("job_name", job.name)
        metadata.update(extra_metadata)
        if cfg and cfg.state is not None:
            state = cfg.state.instantiate(MonitorStateInterface)
        else:
            state = _fallback_state_for(name)
        actions = instantiate_bindings(cfg.actions) if cfg else []
        if state is None and not actions:
            return None
        return MonitorEvent(
            job_id=job.job_id,
            name=name,
            state=state,
            metadata=metadata,
            actions=actions,
        )


@dataclass(kw_only=True)
class _JobSnapshot:
    log_content: str
    last_update: float
    output_contents: dict[str, str] = field(default_factory=dict)


@dataclass(frozen=True)
class _CompiledLogEvent:
    rule: LogEventConfig
    pattern: Pattern[str]

    def instantiate_state(self) -> BaseMonitorState | None:
        if self.rule.state is None:
            return None
        return self.rule.state.instantiate(MonitorStateInterface)


def _compile_pattern(rule: LogEventConfig) -> Pattern[str]:
    if rule.pattern_type == "regex":
        return re.compile(rule.pattern, flags=re.MULTILINE)
    escaped = re.escape(rule.pattern)
    return re.compile(escaped, flags=re.MULTILINE)


def _extract_metadata(match: re.Match[str], rule: LogEventConfig) -> dict[str, Any]:
    extracted: dict[str, Any] = {}
    if not rule.extract_groups:
        return extracted
    for key, group in rule.extract_groups.items():
        if isinstance(group, str) and group == "match":
            extracted[key] = match.group(0)
            continue
        try:
            extracted[key] = match.group(group)
        except (IndexError, KeyError):
            continue
    return extracted


def _fallback_state_for(name: str) -> BaseMonitorState | None:
    key = name.lower()
    if key == "stall":
        return StalledState(StalledStateConfig())
    if key == "timeout":
        return TimeoutState(TimeoutStateConfig())
    if key == "crash":
        return CrashState(CrashStateConfig())
    if key == "success":
        return SuccessState(SuccessStateConfig())
    return None


def default_log_events() -> list[LogEventConfig]:
    """Return generic monitoring signals covering errors and lifecycle
    events."""

    return [
        LogEventConfig(
            name="error",
            pattern=r"(?P<error_type>ERROR|Error|error)[:\s]+(?P<message>.+)",
            pattern_type="regex",
            state=CrashStateConfig(),
            metadata={"severity": "error"},
            extract_groups={
                "error_message": "message",
                "error_kind": "error_type",
            },
        ),
        LogEventConfig(
            name="checkpoint",
            pattern=r"Checkpoint (?:saved|written)[:\s]+(?P<checkpoint>\S+)",
            pattern_type="regex",
            metadata={"kind": "checkpoint"},
            extract_groups={
                "checkpoint_path": "checkpoint",
            },
        ),
        LogEventConfig(
            name="training_complete",
            pattern=r"(Training complete|Training finished)",
            pattern_type="regex",
            state=SuccessStateConfig(),
            metadata={"kind": "completion"},
            extract_groups={"matched": "match"},
        ),
    ]


def default_state_events() -> list[StateEventConfig]:
    """Default synthetic events for stall/crash/timeout/success."""

    return [
        StateEventConfig(
            name="stall",
            state=StalledStateConfig(),
            actions=[],
        ),
        StateEventConfig(
            name="timeout",
            state=TimeoutStateConfig(),
            actions=[],
        ),
        StateEventConfig(
            name="crash",
            state=CrashStateConfig(),
            actions=[],
        ),
        StateEventConfig(
            name="success",
            state=SuccessStateConfig(),
            actions=[
                EventActionConfig(
                    action=LogActionConfig(message="run_finished"),
                )
            ],
        ),
    ]


__all__ = [
    "BaseMonitor",
    "MonitoredJob",
    "MonitorOutcome",
    "MonitorEvent",
    "NullMonitorConfig",
    "LogEventConfig",
    "StateEventConfig",
    "SlurmLogMonitor",
    "SlurmLogMonitorConfig",
    "default_log_events",
    "default_state_events",
]
