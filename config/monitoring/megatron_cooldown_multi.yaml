# Megatron monitoring with multiple cooldown points
# This configuration triggers different cooldown runs at different iteration thresholds
defaults:
  - megatron_production
  - _self_

# Define cooldown iterations and their configurations
metadata:
  cooldown:
    iterations:
      - 10000   # First cooldown: early checkpoint, quick evaluation
      - 50000   # Second cooldown: mid-training, continued training with lower LR
      - 100000  # Third cooldown: late-stage, final fine-tuning
    description: "Multi-stage cooldown at early, mid, and late training"

log_events:
  # Monitor checkpoint saves for cooldown triggers (more reliable than iteration logs)
  - name: checkpoint_saved_cooldown
    pattern: 'successfully saved checkpoint from iteration\s+(?P<iteration>\d+) to (?P<path>\S+)'
    pattern_type: regex
    metadata:
      kind: checkpoint
      trigger: cooldown_check
    extract_groups:
      checkpoint_iteration: iteration
      checkpoint_path: path
    actions:
      # Log the checkpoint save
      - class_name: LogAction
        message: "checkpoint saved at iteration {checkpoint_iteration}"

      # Cooldown 1: Early evaluation at iteration 10000
      - class_name: EventAction
        mode: queue
        conditions:
          - class_name: MetadataCondition
            key: checkpoint_iteration
            equals: "10000"
          - class_name: MaxAttemptsCondition
            max_attempts: 1
          - class_name: FileExistsCondition
            path: "{checkpoint_path}/latest_checkpointed_iteration.txt"
            blocking: true
            timeout_seconds: 600
        action:
          class_name: RunAutoexpAction
          script: scripts/run_autoexp.py
          config_path: "{output_dir}/provenance/unresolved_config.yaml"
          overrides:
            # Load from original checkpoint (absolute path)
            - backend.megatron.load={checkpoint_path}

            # New output directory with cooldown suffix, iteration, and timestamp
            # Note: $$ escapes the interpolation so it's resolved at cooldown run time, not config load time
            - project.base_output_dir={project.base_output_dir}_cooldown_{checkpoint_iteration}_\\${oc.timestring:}

            # Unique project name to avoid conflicts
            - project.name={project.name}_cooldown_early

            # Run quick evaluation only (no training)
            - backend.megatron.train_iters=0
            - backend.megatron.eval_only=true

            # Simplified monitoring
            - monitoring=megatron_basic

      # Cooldown 2: Mid-training continued training with lower LR at iteration 50000
      - class_name: EventAction
        mode: queue
        conditions:
          - class_name: MetadataCondition
            key: checkpoint_iteration
            equals: "50000"
          - class_name: MaxAttemptsCondition
            max_attempts: 1
          - class_name: FileExistsCondition
            path: "{checkpoint_path}/latest_checkpointed_iteration.txt"
            blocking: true
            timeout_seconds: 600
        action:
          class_name: RunAutoexpAction
          script: scripts/run_autoexp.py
          config_path: "{output_dir}/provenance/unresolved_config.yaml"
          overrides:
            # Load from original checkpoint (absolute path)
            - backend.megatron.load={checkpoint_path}

            # New output directory with cooldown suffix, iteration, and timestamp
            # Note: $$ escapes the interpolation so it's resolved at cooldown run time, not config load time
            - project.base_output_dir={project.base_output_dir}_cooldown_{checkpoint_iteration}_\\${oc.timestring:}

            # Unique project name
            - project.name={project.name}_cooldown_mid

            # Continue training with adjusted hyperparameters
            - backend.megatron.train_iters=75000  # Continue to 75k
            - backend.megatron.lr=0.0001  # Reduced LR for fine-tuning
            - backend.megatron.min_lr=0.00001

            # Save will resolve to new base_output_dir automatically

            # Simplified monitoring (no recursive cooldowns)
            - monitoring=megatron_basic

      # Cooldown 3: Late-stage fine-tuning at iteration 100000
      - class_name: EventAction
        mode: queue
        conditions:
          - class_name: MetadataCondition
            key: checkpoint_iteration
            equals: "100000"
          - class_name: MaxAttemptsCondition
            max_attempts: 1
          - class_name: FileExistsCondition
            path: "{checkpoint_path}/latest_checkpointed_iteration.txt"
            blocking: true
            timeout_seconds: 600
        action:
          class_name: RunAutoexpAction
          script: scripts/run_autoexp.py
          config_path: "{output_dir}/provenance/unresolved_config.yaml"
          overrides:
            # Load from original checkpoint (absolute path)
            - backend.megatron.load={checkpoint_path}

            # New output directory with cooldown suffix, iteration, and timestamp
            # Note: $$ escapes the interpolation so it's resolved at cooldown run time, not config load time
            - project.base_output_dir={project.base_output_dir}_cooldown_{checkpoint_iteration}_$${oc.timestring:}

            # Unique project name
            - project.name={project.name}_cooldown_late

            # Final fine-tuning stage
            - backend.megatron.train_iters=120000  # Final 20k iterations
            - backend.megatron.lr=0.00001  # Reduced LR for fine-tuning
            - backend.megatron.min_lr=0.000001
            - backend.megatron.lr_decay_style=constant  # No further LR decay

            # Save will resolve to new base_output_dir automatically

            # Simplified monitoring
            - monitoring=megatron_basic
