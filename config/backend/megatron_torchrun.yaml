defaults:
  - megatron: base
  - _self_

class_name: AutoMegatronBackend
launcher_script: ${.env.RUN_DIR}/pretrain_gpt.py
use_torchrun: true
torchrun_args:
  nproc_per_node: ${slurm.sbatch.gpus_per_node}
  nnodes: ${slurm.sbatch.nodes}
  max_restarts: 0
  tee: 3
  rdzv_endpoint: "$MASTER_ADDR:$MASTER_PORT"
  rdzv_backend: static
  node_rank: "$SLURM_NODEID"
  local_addr: "$LOCAL_ADDR"
  master_addr: "$MASTER_ADDR"
  master_port: "$MASTER_PORT"
env:
  PYTHONPATH: ".:submodules/Megatron-LM"
  PROJECT_DIR: ${oc.env:PROJECT_DIR,"."}
  RUN_DIR: ${.PROJECT_DIR}/submodules/Megatron-LM
  SLURM_NODEID: "$SLURM_NODEID"
  LOCAL_ADDR: "$LOCAL_ADDR"
  MASTER_ADDR: "$MASTER_ADDR"
  MASTER_PORT: "$MASTER_PORT"
