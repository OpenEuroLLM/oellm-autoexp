# @package _global_
defaults:
  - base
  - /backend: megatron_torchrun_localaddr
  - /container: jupiter
  - /slurm: jupiter
  - /backend/megatron: [llama1_8b_qkln,speed_test_jupiter]
  - /sweep: none
  - _self_

backend:
  megatron:
    train_iters: 50
    log_interval: 10
    eval_interval: 1000
    data_path:
     - /e/project1/projectnucleus/franke5/data/datasets/cerebras-SlimPajama-627B/train/merged
    data_cache_path: /e/project1/projectnucleus/poeppel1/data/
    save: null
    load: null
    # FSDP removed (megatron_fsdp config dropped) â€” use standard DDP
    use_megatron_fsdp: false
    use_distributed_optimizer: true
    ckpt_format: torch_dist
  env:
    TOKENIZERS_PARALLELISM: "false"
    TRANSFORMERS_CACHE: ${oc.env:HF_HOME}/transformers
    HUGGINGFACE_HUB_CACHE: ${oc.env:HF_HOME}/hub
    HF_HOME: ${oc.env:HF_HOME}

job:
  name: megatron_jupiter_speed_test
