defaults:
  - base
  - _self_

template_path: templates/lumi.sbatch
launcher_cmd: "{{env_exports}} export MIOPEN_USER_DB_PATH=/tmp/$USER-miopen-cache-$SLURM_NODEID ; \
   export MIOPEN_CUSTOM_CACHE_DIR=$MIOPEN_USER_DB_PATH ; export RANK=$SLURM_PROCID ; export LOCAL_RANK=$SLURM_LOCALID ; \
  ${oc.select:container.runtime,singularity} exec --pwd ${container.pwd} \
  {{bind_flags}}{{env_flags}} ${oc.select:container.image,container.sif}"
srun:
  exclusive: true
  wait: 60
  jobid: "$SLURM_JOB_ID"
launcher_env_passthrough: true
env:
  MACHINE_NAME: LUMI
  MASTER_ADDR: '$(scontrol show hostnames "$SLURM_JOB_NODELIST" | head -n 1)'
  MASTER_PORT: "20074"
  LOCAL_RANK: "0" # will be overridden
  RANK: "0"  # will be overridden
  WORLD_SIZE: ${oc.muli:${..sbatch.nodes},${..sbatch.ntasks_per_node}}
  HSA_ENABLE_SDMA: 0
  NCCL_SOCKET_IFNAME: "hsn0,hsn1,hsn2,hsn3"
  NCCL_NET_GDR_LEVEL: "PHB"
  NVTE_DEBUG: "0"
  NVTE_DEBUG_LEVEL: "0"
  CC: "gcc-12"
  CXX: "g++-12"
  CUDA_DEVICE_MAX_CONNECTIONS: 1
sbatch:
  nodes: 1
  ntasks_per_node: 8
  gpus_per_node: 8
  gres: null
  cpus_per_task: 7
  time: "00:30:00"
  mem: 0
client:
  class_name: SlurmClient
